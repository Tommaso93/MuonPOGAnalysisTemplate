{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Algorithms for Muon Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first check some linear regression algorithms (using the negative mean square error scorer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ML algorithms used for linear regression are: linear regression, Lasso and the ElasticNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.random.seed(42) #Independent from run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the csv into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../MuonPOGAnalysisTemplate/output/bxcut_org.csv'\n",
    "dataframe = read_csv(filename)\n",
    "array = dataframe.values\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first option is divide the train/set in due different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:,0:len(dataframe.columns)-1]\n",
    "Y = array[:,len(dataframe.columns)-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "model = lm.fit(X_train, y_train)\n",
    "predictions = lm.predict(X_test)\n",
    "\n",
    "## The line / model\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, predictions)\n",
    "ax.plot([Y.min(), Y.max()], [Y.min(), Y.max()], 'k--', lw=4)\n",
    "ax.set_xlabel(\"True Values\")\n",
    "ax.set_ylabel(\"Predictions\")\n",
    "plt.show()\n",
    "del ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other option is to use a Kfold for cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "filename = '../MuonPOGAnalysisTemplate/output/bxcut_org.csv'\n",
    "dataframe = read_csv(filename)\n",
    "array = dataframe.values\n",
    "dataframe\n",
    "X = array[:,0:len(dataframe.columns)-1]\n",
    "Y = array[:,len(dataframe.columns)-1]\n",
    "\n",
    "#prepare models\n",
    "models = []\n",
    "models.append(( 'LR' , LinearRegression()))\n",
    "models.append(( 'LAR' , Lasso()))\n",
    "models.append(( 'RIR' , Ridge()))\n",
    "models.append(( 'EN' , ElasticNet()))\n",
    "models.append(('RMR', RandomForestRegressor()))\n",
    "\n",
    "#evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'neg_mean_squared_error'\n",
    "for name,model in models:\n",
    "    kfold = KFold(n_splits=15, random_state=7)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, np.sqrt((-1)*cv_results.mean()), np.sqrt(cv_results.std()))\n",
    "    print(msg)\n",
    "    predicted = cross_val_predict(model, X,Y, cv=kfold)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(Y, predicted, edgecolors=(0, 0, 0))\n",
    "    ax.plot([Y.min(), Y.max()], [Y.min(), Y.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    plt.show()\n",
    "    del ax\n",
    "\n",
    "    # boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non linear regression algorithms are: KNeighbotsRegressor, DecisionTreeRegressor, SVR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "filename = '../MuonPOGAnalysisTemplate/output/bxcut_org.csv'\n",
    "dataframe = read_csv(filename)\n",
    "array = dataframe.values\n",
    "dataframe\n",
    "X = array[:,0:len(dataframe.columns)-1]\n",
    "Y = array[:,len(dataframe.columns)-1]\n",
    "\n",
    "#prepare models\n",
    "models = []\n",
    "models.append(( 'KNR' , KNeighborsRegressor()))\n",
    "models.append(( 'DTR' , DecisionTreeRegressor()))\n",
    "models.append(( 'SVR' , SVR()))\n",
    "models.append(( 'RFR' , RandomForestRegressor()))\n",
    "\n",
    "#evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'mean_squared_error'\n",
    "for name,model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    rmse = np.sqrt((-1)*cv_results.mean())\n",
    "    msg = \"%s: %f (%f)\" % (name, rmse, np.sqrt(cv_results.std()))\n",
    "    print(msg)\n",
    "    predicted = cross_val_predict(model, X, Y, cv=kfold)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(Y, predicted, edgecolors=(0, 0, 0))\n",
    "    ax.plot([Y.min(), Y.max()], [Y.min(), Y.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    plt.show()\n",
    "    del ax\n",
    "\n",
    "    # boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is no clear prediction of target label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with stratified shuffle and split cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another technique that we can use to split train/test dataset is the so called *Stratified Shuffle split* cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shuffle-split iterator will generate a user defined number of independent train / test dataset splits. Samples are first shuffled and then split into a pair of train and test sets.\n",
    "The word **stratified** simply groups the dataset into similar distributed entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first idea is to merge the 5-case primitive and the 1-case primitive muons in the contiguous group (4 and 2 respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label those below 2 as 2\n",
    "# Label those above 4 as 4\n",
    "dataframe[\"n_Primitive_category\"] = np.ceil(dataframe[\"n_Primitive\"])\n",
    "dataframe[\"n_Primitive_category\"].where(dataframe[\"n_Primitive\"] < 5, 4.0, inplace=True)\n",
    "dataframe[\"n_Primitive_category\"].where(dataframe[\"n_Primitive\"] > 1, 2.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to perform the stratified shuffle split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[\"n_Primitive_category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=8, test_size=0.3, random_state=42)\n",
    "for train_index, test_index in split.split(dataframe, dataframe[\"n_Primitive_category\"]):\n",
    "    strat_train_set = dataframe.loc[train_index]\n",
    "    strat_test_set = dataframe.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to remove the temporary column that is useless to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"n_Primitive_category\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see how the new dataset is formed (both for training and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we divide (both training and test) into predictors and labels (supervised ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = strat_train_set.drop(\"genParticle.pt\",axis=1)\n",
    "y_train = strat_train_set[\"genParticle.pt\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = strat_test_set.drop(\"genParticle.pt\",axis=1)\n",
    "y_test = strat_test_set[\"genParticle.pt\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we apply the ML regression algorithms in sequence on a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = []\n",
    "models.append(( 'LR' , LinearRegression()))\n",
    "models.append(( 'LAR' , Lasso()))\n",
    "models.append(( 'RIR' , Ridge()))\n",
    "models.append(( 'EN' , ElasticNet()))\n",
    "models.append(( 'DTR' , DecisionTreeRegressor(random_state=42)))\n",
    "models.append(( 'KNR' , KNeighborsRegressor()))\n",
    "models.append(( 'SVR' , SVR()))\n",
    "models.append(( 'RFR' , RandomForestRegressor()))\n",
    "\n",
    "#evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'neg_mean_squared_error'\n",
    "for name,model in models:\n",
    "    \n",
    "    M_model = model.fit(X_train,y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    \n",
    "    lin_mse = mean_squared_error(y_test, prediction)\n",
    "    lin_rmse = np.sqrt(lin_mse)\n",
    "    msg = \"%s: %f\" % (name, lin_rmse)\n",
    "    print(msg)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(y_test, prediction, edgecolors=(0, 0, 0))\n",
    "    ax.plot([Y.min(), Y.max()], [Y.min(), Y.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Measured P_t(GeV)')\n",
    "    ax.set_ylabel('Predicted P_t(GeV)')\n",
    "    ax.set_title(name)\n",
    "    plt.show()\n",
    "    del ax\n",
    "    if (name == 'RFR'):\n",
    "        d = {'col1': y_test, 'col2': prediction}\n",
    "        compare = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
